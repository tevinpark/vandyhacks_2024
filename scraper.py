# -*- coding: utf-8 -*-
"""vandyhacks.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B7FE7fovMT3abH6j-O7QW2kfrUM5zGUk
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import json
import urllib.parse
import time
from google.colab import files

url = "https://as.vanderbilt.edu/math/people/"
response = requests.get(url)
html_content = response.content

soup = BeautifulSoup(html_content, 'html.parser')

name_cells = soup.find_all('td', {'class': 'biolink'})

names = []
for cell in name_cells:
    name = cell.find('a').text.strip()
    if name == "Constantine Tsinakis (Κώστας Τσινάκης)":
      names.append("Constantine Tsinakis")
    elif name == "Larry G. Rolen":
      names.append("Rolen Larry")
    else:
      names.append(name)

names

def scrape_professor_info(link):
    try:
        response = requests.get(link)
        soup = BeautifulSoup(response.text, "html.parser")

        professor_name = soup.select_one(".NameTitle__Name-dowf0z-0").get_text() if soup.select_one(".NameTitle__Name-dowf0z-0") else 'N/A'
        department = soup.select_one(".NameTitle__Title-dowf0z-1").get_text() if soup.select_one(".NameTitle__Title-dowf0z-1") else 'N/A'
        overall_quality = soup.select_one(".RatingValue__Numerator-qw8sqy-2").get_text() if soup.select_one(".RatingValue__Numerator-qw8sqy-2") else 'N/A'

        feedback_items = soup.select(".FeedbackItem__FeedbackNumber-uof32n-1")
        take_again = feedback_items[0].get_text() if len(feedback_items) > 0 else 'N/A'
        difficulty = feedback_items[1].get_text() if len(feedback_items) > 1 else 'N/A'

        tags = soup.select('span.Tag-bs9vf4-0')
        tags_list = [tag.get_text() for tag in tags[:5]]

        return {
            'Name': professor_name,
            'Department': department,
            'Overall Quality': overall_quality,
            'Take Again': take_again[:-1],
            'Difficulty': difficulty,
            'Tags': tags_list
        }
    except Exception as e:
        print(f"Error scraping {link}: {e}")
        return None

def get_vanderbilt_professors_info(names):
    links = []
    professors_info = []  # List to store all professor info

    for name in names:
        base_url = "https://www.ratemyprofessors.com/search/professors/4002"
        query = {'q': name}
        search_url = f"{base_url}?{urllib.parse.urlencode(query)}"

        try:
            response = requests.get(search_url)
            soup = BeautifulSoup(response.text, 'html.parser')

            professor_link = soup.select_one('a[href^="/professor/"]')

            if professor_link:
                full_link = "https://www.ratemyprofessors.com" + professor_link['href']
                links.append(full_link)

                professor_info = scrape_professor_info(full_link)
                if professor_info:
                    professors_info.append(professor_info)
                else:
                    print(f"Failed to scrape info for {name}")
            else:
                print(f"No link found for {name}")

            time.sleep(2)

        except Exception as e:
            print(f"Error processing {name}: {e}")

    return professors_info

data = get_vanderbilt_professors_info(names)
print(data)