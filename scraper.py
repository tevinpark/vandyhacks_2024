# -*- coding: utf-8 -*-
"""scraping.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B7FE7fovMT3abH6j-O7QW2kfrUM5zGUk
"""

import requests
from bs4 import BeautifulSoup
import json
import urllib.parse
import time
from google.colab import files

url = "https://as.vanderbilt.edu/cinema-media-arts/core-faculty/"
response = requests.get(url)
html_content = response.content

soup = BeautifulSoup(html_content, 'html.parser')

name_cells = soup.find_all('h4', {'class': 'row'})

names = []
for cell in name_cells:
    name = cell.find('a').text.strip()
    names.append(name)

names

def scrape_professor_info(link):
    try:
        response = requests.get(link)
        soup = BeautifulSoup(response.text, "html.parser")

        professor_name = soup.select_one(".NameTitle__Name-dowf0z-0").get_text() if soup.select_one(".NameTitle__Name-dowf0z-0") else 'N/A'
        department = soup.select_one(".NameTitle__Title-dowf0z-1").get_text() if soup.select_one(".NameTitle__Title-dowf0z-1") else 'N/A'
        overall_quality = soup.select_one(".RatingValue__Numerator-qw8sqy-2").get_text() if soup.select_one(".RatingValue__Numerator-qw8sqy-2") else 'N/A'

        feedback_items = soup.select(".FeedbackItem__FeedbackNumber-uof32n-1")
        take_again = feedback_items[0].get_text() if len(feedback_items) > 0 else "N/A"
        difficulty = feedback_items[1].get_text() if len(feedback_items) >= 1 else "N/A"

        tags = soup.select('span.Tag-bs9vf4-0')
        tags_list = [tag.get_text() for tag in tags[:5]]

        ratings_tag = soup.select_one('a[href="#ratingsList"]')
        number_of_reviews = ratings_tag.get_text(strip=True)[:-7].strip() if ratings_tag else 'N/A'

        if (department == 'Professor in the Business department at Vanderbilt University') and (overall_quality != "N/A" and take_again != "N/A" and difficulty != "N/A"and number_of_reviews != "N/A"):
            return {
                'Name': professor_name,
                'Department': "Buisiness",
                'OverallQuality': overall_quality,
                'TakeAgain': take_again[:-1],
                'Difficulty': difficulty,
                'Tags': tags_list,
                'NumberOfReviews': number_of_reviews
            }
    except Exception as e:
        print(f"Error scraping {link}: {e}")
        return None

def get_vanderbilt_professors_info(names):
    links = []
    professors_info = []

    for name in names:
        base_url = "https://www.ratemyprofessors.com/search/professors/4002"
        query = {'q': name}
        search_url = f"{base_url}?{urllib.parse.urlencode(query)}"

        try:
            response = requests.get(search_url)
            soup = BeautifulSoup(response.text, 'html.parser')

            professor_link = soup.select_one('a[href^="/professor/"]')

            if professor_link:
                full_link = "https://www.ratemyprofessors.com" + professor_link['href']
                links.append(full_link)

                professor_info = scrape_professor_info(full_link)
                if professor_info:
                    professors_info.append(professor_info)
                else:
                    print(f"Failed to scrape info for {name}")
            else:
                print(f"No link found for {name}")

            time.sleep(2)

        except Exception as e:
            print(f"Error processing {name}: {e}")

    return professors_info

def main():
  data = get_vanderbilt_professors_info(names)
  print(data)

  with open("buisiness.json", "w") as final:
    for professor in data:
      json.dump(professor, final)
      final.write('\n')

  files.download('buisiness.json')

if __name__ == "__main__":
    main()
